[hadoop@ip-172-31-13-32 ~]$ spark-submit spark_output_to_edge_vertices.py 
21/05/07 08:50:29 INFO SparkContext: Running Spark version 2.4.4
21/05/07 08:50:29 INFO SparkContext: Submitted application: genie3
21/05/07 08:50:29 INFO SecurityManager: Changing view acls to: hadoop
21/05/07 08:50:29 INFO SecurityManager: Changing modify acls to: hadoop
21/05/07 08:50:29 INFO SecurityManager: Changing view acls groups to: 
21/05/07 08:50:29 INFO SecurityManager: Changing modify acls groups to: 
21/05/07 08:50:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
21/05/07 08:50:30 INFO Utils: Successfully started service 'sparkDriver' on port 45549.
21/05/07 08:50:30 INFO SparkEnv: Registering MapOutputTracker
21/05/07 08:50:30 INFO SparkEnv: Registering BlockManagerMaster
21/05/07 08:50:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/07 08:50:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/07 08:50:30 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-923245f9-a3ef-4c7a-a727-8179c39b5037
21/05/07 08:50:30 INFO MemoryStore: MemoryStore started with capacity 1028.8 MB
21/05/07 08:50:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/07 08:50:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/05/07 08:50:30 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ip-172-31-13-32.ec2.internal:4040
21/05/07 08:50:30 INFO Utils: Using initial executors = 50, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
21/05/07 08:50:31 INFO RMProxy: Connecting to ResourceManager at ip-172-31-13-32.ec2.internal/172.31.13.32:8032
21/05/07 08:50:32 INFO Client: Requesting a new application from cluster with 2 NodeManagers
21/05/07 08:50:32 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (12288 MB per container)
21/05/07 08:50:32 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
21/05/07 08:50:32 INFO Client: Setting up container launch context for our AM
21/05/07 08:50:32 INFO Client: Setting up the launch environment for our AM container
21/05/07 08:50:32 INFO Client: Preparing resources for our AM container
21/05/07 08:50:32 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
21/05/07 08:50:34 INFO Client: Uploading resource file:/mnt/tmp/spark-c0b6f5b3-58f7-4116-a841-88929d9d0142/__spark_libs__5968507748659800918.zip -> hdfs://ip-172-31-13-32.ec2.internal:8020/user/hadoop/.sparkStaging/application_1620373576758_0002/__spark_libs__5968507748659800918.zip
21/05/07 08:50:35 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-13-32.ec2.internal:8020/user/hadoop/.sparkStaging/application_1620373576758_0002/pyspark.zip
21/05/07 08:50:35 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://ip-172-31-13-32.ec2.internal:8020/user/hadoop/.sparkStaging/application_1620373576758_0002/py4j-0.10.7-src.zip
21/05/07 08:50:36 INFO Client: Uploading resource file:/mnt/tmp/spark-c0b6f5b3-58f7-4116-a841-88929d9d0142/__spark_conf__5324820325639035116.zip -> hdfs://ip-172-31-13-32.ec2.internal:8020/user/hadoop/.sparkStaging/application_1620373576758_0002/__spark_conf__.zip
21/05/07 08:50:36 INFO SecurityManager: Changing view acls to: hadoop
21/05/07 08:50:36 INFO SecurityManager: Changing modify acls to: hadoop
21/05/07 08:50:36 INFO SecurityManager: Changing view acls groups to: 
21/05/07 08:50:36 INFO SecurityManager: Changing modify acls groups to: 
21/05/07 08:50:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
21/05/07 08:50:38 INFO Client: Submitting application application_1620373576758_0002 to ResourceManager
21/05/07 08:50:38 INFO YarnClientImpl: Submitted application application_1620373576758_0002
21/05/07 08:50:38 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1620373576758_0002 and attemptId None
21/05/07 08:50:39 INFO Client: Application report for application_1620373576758_0002 (state: ACCEPTED)
21/05/07 08:50:39 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1620377438200
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-13-32.ec2.internal:20888/proxy/application_1620373576758_0002/
	 user: hadoop
21/05/07 08:50:40 INFO Client: Application report for application_1620373576758_0002 (state: ACCEPTED)
21/05/07 08:50:41 INFO Client: Application report for application_1620373576758_0002 (state: ACCEPTED)
21/05/07 08:50:42 INFO Client: Application report for application_1620373576758_0002 (state: ACCEPTED)
21/05/07 08:50:43 INFO Client: Application report for application_1620373576758_0002 (state: RUNNING)
21/05/07 08:50:43 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.15.215
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1620377438200
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-13-32.ec2.internal:20888/proxy/application_1620373576758_0002/
	 user: hadoop
21/05/07 08:50:43 INFO YarnClientSchedulerBackend: Application application_1620373576758_0002 has started running.
21/05/07 08:50:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33717.
21/05/07 08:50:43 INFO NettyBlockTransferService: Server created on ip-172-31-13-32.ec2.internal:33717
21/05/07 08:50:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/07 08:50:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-172-31-13-32.ec2.internal, 33717, None)
21/05/07 08:50:43 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-13-32.ec2.internal:33717 with 1028.8 MB RAM, BlockManagerId(driver, ip-172-31-13-32.ec2.internal, 33717, None)
21/05/07 08:50:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-172-31-13-32.ec2.internal, 33717, None)
21/05/07 08:50:43 INFO BlockManager: external shuffle service port = 7337
21/05/07 08:50:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-172-31-13-32.ec2.internal, 33717, None)
21/05/07 08:50:43 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-172-31-13-32.ec2.internal, PROXY_URI_BASES -> http://ip-172-31-13-32.ec2.internal:20888/proxy/application_1620373576758_0002), /proxy/application_1620373576758_0002
21/05/07 08:50:43 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
21/05/07 08:50:43 INFO JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
21/05/07 08:50:43 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
21/05/07 08:50:43 INFO EventLoggingListener: Logging events to hdfs:/var/log/spark/apps/application_1620373576758_0002
21/05/07 08:50:43 INFO Utils: Using initial executors = 50, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
21/05/07 08:50:43 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/05/07 08:50:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 236.9 KB, free 1028.6 MB)
21/05/07 08:50:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.8 KB, free 1028.6 MB)
21/05/07 08:50:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-172-31-13-32.ec2.internal:33717 (size: 23.8 KB, free: 1028.8 MB)
21/05/07 08:50:44 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
21/05/07 08:50:44 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/05/07 08:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.DirectFileOutputCommitter
21/05/07 08:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/07 08:50:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/07 08:50:44 INFO DirectFileOutputCommitter: Direct Write: DISABLED
21/05/07 08:50:44 INFO GPLNativeCodeLoader: Loaded native gpl library
21/05/07 08:50:44 INFO LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 5f788d5e8f90539ee331702c753fa250727128f4]
21/05/07 08:50:44 INFO FileInputFormat: Total input files to process : 1
21/05/07 08:50:45 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/05/07 08:50:45 INFO DAGScheduler: Registering RDD 3 (coalesce at NativeMethodAccessorImpl.java:0)
21/05/07 08:50:45 INFO DAGScheduler: Got job 0 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/05/07 08:50:45 INFO DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopWriter.scala:78)
21/05/07 08:50:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/07 08:50:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/05/07 08:50:45 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at coalesce at NativeMethodAccessorImpl.java:0), which has no missing parents
21/05/07 08:50:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.3 KB, free 1028.6 MB)
21/05/07 08:50:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 1028.6 MB)
21/05/07 08:50:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ip-172-31-13-32.ec2.internal:33717 (size: 5.0 KB, free: 1028.8 MB)
21/05/07 08:50:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1201
21/05/07 08:50:45 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at coalesce at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))
21/05/07 08:50:45 INFO YarnScheduler: Adding task set 0.0 with 3 tasks
21/05/07 08:50:47 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.31.15.215:34482) with ID 1
21/05/07 08:50:48 INFO ExecutorAllocationManager: New executor 1 has registered (new total is 1)
21/05/07 08:50:48 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, ip-172-31-15-215.ec2.internal, executor 1, partition 1, NODE_LOCAL, 7928 bytes)
21/05/07 08:50:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 1, ip-172-31-15-215.ec2.internal, executor 1, partition 0, RACK_LOCAL, 7928 bytes)
21/05/07 08:50:48 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, ip-172-31-15-215.ec2.internal, executor 1, partition 2, RACK_LOCAL, 7928 bytes)
21/05/07 08:50:48 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-15-215.ec2.internal:34067 with 5.4 GB RAM, BlockManagerId(1, ip-172-31-15-215.ec2.internal, 34067, None)
21/05/07 08:50:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ip-172-31-15-215.ec2.internal:34067 (size: 5.0 KB, free: 5.4 GB)
21/05/07 08:50:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-172-31-15-215.ec2.internal:34067 (size: 23.8 KB, free: 5.4 GB)
21/05/07 08:50:49 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.31.13.20:49416) with ID 2
21/05/07 08:50:49 INFO ExecutorAllocationManager: New executor 2 has registered (new total is 2)
21/05/07 08:50:50 INFO BlockManagerMasterEndpoint: Registering block manager ip-172-31-13-20.ec2.internal:39347 with 5.4 GB RAM, BlockManagerId(2, ip-172-31-13-20.ec2.internal, 39347, None)
21/05/07 08:51:13 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 25331 ms on ip-172-31-15-215.ec2.internal (executor 1) (1/3)
21/05/07 08:51:13 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 53563
21/05/07 08:51:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 1) in 36516 ms on ip-172-31-15-215.ec2.internal (executor 1) (2/3)
21/05/07 08:51:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 0) in 38570 ms on ip-172-31-15-215.ec2.internal (executor 1) (3/3)
21/05/07 08:51:26 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/05/07 08:51:26 INFO DAGScheduler: ShuffleMapStage 0 (coalesce at NativeMethodAccessorImpl.java:0) finished in 41.460 s
21/05/07 08:51:26 INFO DAGScheduler: looking for newly runnable stages
21/05/07 08:51:26 INFO DAGScheduler: running: Set()
21/05/07 08:51:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/05/07 08:51:26 INFO DAGScheduler: failed: Set()
21/05/07 08:51:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
21/05/07 08:51:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 76.7 KB, free 1028.5 MB)
21/05/07 08:51:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.9 KB, free 1028.5 MB)
21/05/07 08:51:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ip-172-31-13-32.ec2.internal:33717 (size: 29.9 KB, free: 1028.8 MB)
21/05/07 08:51:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1201
21/05/07 08:51:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/05/07 08:51:26 INFO YarnScheduler: Adding task set 1.0 with 1 tasks
21/05/07 08:51:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 3, ip-172-31-15-215.ec2.internal, executor 1, partition 0, NODE_LOCAL, 7949 bytes)
21/05/07 08:51:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ip-172-31-15-215.ec2.internal:34067 (size: 29.9 KB, free: 5.4 GB)
21/05/07 08:51:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.31.15.215:34482
21/05/07 08:51:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 3) in 766 ms on ip-172-31-15-215.ec2.internal (executor 1) (1/1)
21/05/07 08:51:27 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/07 08:51:27 INFO DAGScheduler: ResultStage 1 (runJob at SparkHadoopWriter.scala:78) finished in 0.795 s
21/05/07 08:51:27 INFO DAGScheduler: Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 42.379869 s
21/05/07 08:51:27 INFO SparkHadoopWriter: Job job_20210507085044_0009 committed.
21/05/07 08:51:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.DirectFileOutputCommitter
21/05/07 08:51:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/07 08:51:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/07 08:51:27 INFO DirectFileOutputCommitter: Direct Write: DISABLED
21/05/07 08:51:27 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/05/07 08:51:27 INFO DAGScheduler: Registering RDD 11 (distinct at /home/hadoop/spark_output_to_edge_vertices.py:22)
21/05/07 08:51:27 INFO DAGScheduler: Registering RDD 15 (coalesce at NativeMethodAccessorImpl.java:0)
21/05/07 08:51:27 INFO DAGScheduler: Got job 1 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/05/07 08:51:27 INFO DAGScheduler: Final stage: ResultStage 4 (runJob at SparkHadoopWriter.scala:78)
21/05/07 08:51:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
21/05/07 08:51:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
21/05/07 08:51:27 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[11] at distinct at /home/hadoop/spark_output_to_edge_vertices.py:22), which has no missing parents
21/05/07 08:51:27 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.1 KB, free 1028.5 MB)
21/05/07 08:51:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.0 KB, free 1028.5 MB)
21/05/07 08:51:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-13-32.ec2.internal:33717 (size: 7.0 KB, free: 1028.8 MB)
21/05/07 08:51:27 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1201
21/05/07 08:51:27 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 2 (PairwiseRDD[11] at distinct at /home/hadoop/spark_output_to_edge_vertices.py:22) (first 15 tasks are for partitions Vector(0, 1, 2))
21/05/07 08:51:27 INFO YarnScheduler: Adding task set 2.0 with 3 tasks
21/05/07 08:51:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, ip-172-31-13-20.ec2.internal, executor 2, partition 0, NODE_LOCAL, 7928 bytes)
21/05/07 08:51:27 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, ip-172-31-15-215.ec2.internal, executor 1, partition 1, NODE_LOCAL, 7928 bytes)
21/05/07 08:51:27 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 6, ip-172-31-13-20.ec2.internal, executor 2, partition 2, NODE_LOCAL, 7928 bytes)
21/05/07 08:51:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-15-215.ec2.internal:34067 (size: 7.0 KB, free: 5.4 GB)
21/05/07 08:51:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-172-31-13-20.ec2.internal:39347 (size: 7.0 KB, free: 5.4 GB)
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 48
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 25
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 21
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 1
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 20
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 44
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 33
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 28
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 6
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 40
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 23
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 14
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 7
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 34
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 39
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 43
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 47
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 4
21/05/07 08:51:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-172-31-13-20.ec2.internal:39347 (size: 23.8 KB, free: 5.4 GB)
21/05/07 08:51:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ip-172-31-13-32.ec2.internal:33717 in memory (size: 29.9 KB, free: 1028.8 MB)
21/05/07 08:51:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ip-172-31-15-215.ec2.internal:34067 in memory (size: 29.9 KB, free: 5.4 GB)
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 15
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 29
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 11
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 8
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 49
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 35
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 46
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 17
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 19
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 32
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 24
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 30
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 5
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 45
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 2
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 37
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 22
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 10
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 27
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 13
21/05/07 08:51:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ip-172-31-13-32.ec2.internal:33717 in memory (size: 5.0 KB, free: 1028.8 MB)
21/05/07 08:51:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ip-172-31-15-215.ec2.internal:34067 in memory (size: 5.0 KB, free: 5.4 GB)
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 9
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 26
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 38
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 31
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 12
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 50
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 3
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 42
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 36
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 18
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 16
21/05/07 08:51:28 INFO ContextCleaner: Cleaned accumulator 41
21/05/07 08:51:47 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 6) in 20059 ms on ip-172-31-13-20.ec2.internal (executor 2) (1/3)
21/05/07 08:51:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 23866 ms on ip-172-31-15-215.ec2.internal (executor 1) (2/3)
21/05/07 08:51:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 28086 ms on ip-172-31-13-20.ec2.internal (executor 2) (3/3)
21/05/07 08:51:55 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/05/07 08:51:55 INFO DAGScheduler: ShuffleMapStage 2 (distinct at /home/hadoop/spark_output_to_edge_vertices.py:22) finished in 28.100 s
21/05/07 08:51:55 INFO DAGScheduler: looking for newly runnable stages
21/05/07 08:51:55 INFO DAGScheduler: running: Set()
21/05/07 08:51:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
21/05/07 08:51:55 INFO DAGScheduler: failed: Set()
21/05/07 08:51:55 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[15] at coalesce at NativeMethodAccessorImpl.java:0), which has no missing parents
21/05/07 08:51:55 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 1028.6 MB)
21/05/07 08:51:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.1 KB, free 1028.6 MB)
21/05/07 08:51:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ip-172-31-13-32.ec2.internal:33717 (size: 5.1 KB, free: 1028.8 MB)
21/05/07 08:51:55 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1201
21/05/07 08:51:55 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[15] at coalesce at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2))
21/05/07 08:51:55 INFO YarnScheduler: Adding task set 3.0 with 3 tasks
21/05/07 08:51:55 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 7, ip-172-31-13-20.ec2.internal, executor 2, partition 0, NODE_LOCAL, 7662 bytes)
21/05/07 08:51:55 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 8, ip-172-31-13-20.ec2.internal, executor 2, partition 1, NODE_LOCAL, 7662 bytes)
21/05/07 08:51:55 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 9, ip-172-31-13-20.ec2.internal, executor 2, partition 2, NODE_LOCAL, 7662 bytes)
21/05/07 08:51:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ip-172-31-13-20.ec2.internal:39347 (size: 5.1 KB, free: 5.4 GB)
21/05/07 08:51:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.31.13.20:49416
21/05/07 08:51:55 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 9) in 159 ms on ip-172-31-13-20.ec2.internal (executor 2) (1/3)
21/05/07 08:51:55 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 8) in 160 ms on ip-172-31-13-20.ec2.internal (executor 2) (2/3)
21/05/07 08:51:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 7) in 170 ms on ip-172-31-13-20.ec2.internal (executor 2) (3/3)
21/05/07 08:51:55 INFO YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/07 08:51:55 INFO DAGScheduler: ShuffleMapStage 3 (coalesce at NativeMethodAccessorImpl.java:0) finished in 0.178 s
21/05/07 08:51:55 INFO DAGScheduler: looking for newly runnable stages
21/05/07 08:51:55 INFO DAGScheduler: running: Set()
21/05/07 08:51:55 INFO DAGScheduler: waiting: Set(ResultStage 4)
21/05/07 08:51:55 INFO DAGScheduler: failed: Set()
21/05/07 08:51:55 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
21/05/07 08:51:55 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 76.7 KB, free 1028.5 MB)
21/05/07 08:51:55 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.8 KB, free 1028.5 MB)
21/05/07 08:51:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ip-172-31-13-32.ec2.internal:33717 (size: 29.8 KB, free: 1028.8 MB)
21/05/07 08:51:55 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1201
21/05/07 08:51:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/05/07 08:51:55 INFO YarnScheduler: Adding task set 4.0 with 1 tasks
21/05/07 08:51:55 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, ip-172-31-13-20.ec2.internal, executor 2, partition 0, NODE_LOCAL, 7949 bytes)
21/05/07 08:51:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ip-172-31-13-20.ec2.internal:39347 (size: 29.8 KB, free: 5.4 GB)
21/05/07 08:51:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.31.13.20:49416
21/05/07 08:51:56 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 208 ms on ip-172-31-13-20.ec2.internal (executor 2) (1/1)
21/05/07 08:51:56 INFO YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/05/07 08:51:56 INFO DAGScheduler: ResultStage 4 (runJob at SparkHadoopWriter.scala:78) finished in 0.225 s
21/05/07 08:51:56 INFO DAGScheduler: Job 1 finished: runJob at SparkHadoopWriter.scala:78, took 28.515697 s
21/05/07 08:51:56 INFO SparkHadoopWriter: Job job_20210507085127_0021 committed.
21/05/07 08:51:56 INFO SparkContext: Invoking stop() from shutdown hook
21/05/07 08:51:56 INFO SparkUI: Stopped Spark web UI at http://ip-172-31-13-32.ec2.internal:4040
21/05/07 08:51:56 INFO YarnClientSchedulerBackend: Interrupting monitor thread
21/05/07 08:51:56 INFO YarnClientSchedulerBackend: Shutting down all executors
21/05/07 08:51:56 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
21/05/07 08:51:56 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
21/05/07 08:51:56 INFO YarnClientSchedulerBackend: Stopped
21/05/07 08:51:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/07 08:51:56 INFO MemoryStore: MemoryStore cleared
21/05/07 08:51:56 INFO BlockManager: BlockManager stopped
21/05/07 08:51:56 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/07 08:51:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/07 08:51:56 INFO SparkContext: Successfully stopped SparkContext
21/05/07 08:51:56 INFO ShutdownHookManager: Shutdown hook called
21/05/07 08:51:56 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-c0b6f5b3-58f7-4116-a841-88929d9d0142/pyspark-79dc3432-36a4-4805-97d5-f0385b50b660
21/05/07 08:51:56 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-c0b6f5b3-58f7-4116-a841-88929d9d0142
21/05/07 08:51:56 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-3d58a76f-ab56-4c1d-8bce-e0ca6a8fc4e1